%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Network as a matrix channel} \label{chap:network}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

To clarify the difference between scalar coding and vector coding,
we firstly represent the network as a matrix channel, then secondly
we show the advantages of vector coding in choosing coding coefficients,
and we finally introduce a gap in alphabet size between scalar coding's
and vector's coding solutions, which supports in showing an improvement
in the alphabet size for the vector solutions. 

\section{Definition of scalar coding and vector coding}

To formulate this description, the source has a set of disjoint messages
referred to packets which are either symbols from $\ensuremath{\mathbb{F}}_{q^{t}}$
(scalar coding) or vectors of length $t$ over $\ensuremath{\mathbb{F}}_{q}$
(vector coding). Each link in the network carries functions of the
packets, and a \textit{network code} is a set of these functions.
The network code is called \textit{linear} if all the functions are
linear and nonlinear otherwise. Each receiver $R_{j},j\in\left\{ 1,\ldots,N\right\} $
requests a subset of the source's length-$h$ messages, and this subset
is called \textit{a packet}. Through all the functions on the links
from the source to each receiver, the receiver obtains several linear
combinations of the $h$ messages to form a linear system of equations
for its requested packets. The coefficients of a linear combination
are called \textit{global coding vectors}. The linear equation system
that any receiver $R_{j}$ has to solve is as following:

\begin{equation}
\begin{array}{c|c}
Scalar & Vector\\
\underset{\ensuremath{\mathbb{F}}_{q^{t}}^{s}}{\underbrace{\left[\begin{array}{c}
y_{j_{1}}\\
\vdots\\
y_{j_{s}}
\end{array}\right]}}=\underset{\ensuremath{\mathbb{F}}_{q^{t}}^{s\times h}}{\underbrace{\boldsymbol{A}_{j}}}\cdot\underset{\ensuremath{\mathbb{F}}_{q^{t}}^{h}}{\underbrace{\left[\begin{array}{c}
x_{1}\\
\vdots\\
x_{h}
\end{array}\right]}} & \underset{\ensuremath{\mathbb{F}}_{q}^{st}}{\underbrace{\left[\begin{array}{c}
\underline{y}_{j_{1}}\\
\vdots\\
\underline{y}_{j_{s}}
\end{array}\right]}}=\underset{\ensuremath{\mathbb{F}}_{q}^{st\times th}}{\underbrace{\boldsymbol{A}_{j}}}\cdot\underset{\ensuremath{\mathbb{F}}_{q}^{th}}{\underbrace{\left[\begin{array}{c}
\underline{x}_{1}\\
\vdots\\
\underline{x}_{h}
\end{array}\right]}}
\end{array}\label{eq:linear_system}
\end{equation}

The transfer matrix $\boldsymbol{A}_{j}$ contains the links' \textit{global
coding vectors}, which are combined by the coefficients of linear
combinations on $\alpha l$ links from $\alpha$ nodes and $\epsilon$
direct-links to the corresponding receiver $R_{j}$:

\[
\begin{array}{c|c}
Scalar & Vector\\
\boldsymbol{A}_{j}=\left[\begin{array}{c}
\underline{a}_{j_{1}}\\
\vdots\\
\underline{a}_{j_{\alpha l}}\\
\underline{b}_{j_{1}}\\
\vdots\\
\underline{b}_{j_{\epsilon}}
\end{array}\right] & \boldsymbol{A}_{j}=\left[\begin{array}{c}
\boldsymbol{A}_{j_{1}}\\
\vdots\\
\boldsymbol{A}_{j_{\alpha l}}\\
\boldsymbol{B}_{j_{1}}\\
\vdots\\
\boldsymbol{B}_{j_{\epsilon}}
\end{array}\right]
\end{array}
\]

In general, the network is represented as a matrix channel:
\begin{defn}
Network As Matrix Channel

The channel output can be written as: $\boldsymbol{Y}_{j}=\boldsymbol{A}_{j}\cdot\boldsymbol{X}$
\end{defn}
A network is \textit{sovable} or a network code is a \textit{solution},
if each receiver can reconstruct its requested messages or solve the
system with a unique solution for scalars $x_{1},\ldots,x_{h}$, or
vectors $\underline{x}_{1},\ldots,\underline{x}_{h}$. Therefore,
we want to find global coding vectors such that the matrix $\boldsymbol{A}_{j}$
has full-rank for every $j=1,\ldots,N$, and such that $q^{t}$ is
minimized. The solutions of scalar and vector coding are always equivalent
due to our use of scalar symbols from $\ensuremath{\mathbb{F}}_{q^{t}}$,
which is explained better in Example~\ref{ex:scalar_vector_mapping}.
Because we reconstruct $\boldsymbol{X}$ with knowing $\boldsymbol{A}_{j}$,
i.e. the network structure is known, 
\begin{example}
\label{ex:scalar_vector_mapping} 

Given $h=3,q=2,t=2$, we consider the extension field $\ensuremath{\mathbb{F}}_{q^{t}=2^{2}}$.
The example shows how mapping messages from scalar coding to vector
coding.

We use the table of the extension field $\ensuremath{\mathbb{F}}_{2^{2}}$
with the primitive polynomial $f(x)=x^{2}+x+1$ (CITATION):
\end{example}
\begin{tabular}{|c|c|c|}
\hline 
power of $\alpha$ & polynomial & binary vector\tabularnewline
\hline 
- & 0 & 00\tabularnewline
\hline 
$\alpha^{0}$ & 1 & 01\tabularnewline
\hline 
$\alpha^{1}$ & $\alpha$ & 10\tabularnewline
\hline 
$\alpha^{2}$ & $\alpha+1$ & 11\tabularnewline
\hline 
\end{tabular}

For scalar coding, the messages are $x_{1},\ldots,x_{h=3}\in\ensuremath{\mathbb{F}}_{2^{2}}$
, and for vector coding the messages are $\underline{x}_{1},\ldots,\underline{x}_{h=3}\in\ensuremath{\mathbb{F}}_{2}^{2}$.
From the polynomial column, let's choose arbitrarily a scalar vector
$\underline{x}_{scalar}=(x_{1},x_{2},x_{3})=(1,\alpha,\alpha+1)$.
Then, we map it to $\underline{x}_{vector}=(\underline{x}_{1},\underline{x}_{2},\underline{x}_{3})$
by using the binary vector column as following:

\[
\left[\begin{array}{c}
x_{1}=1\\
x_{2}=\alpha\\
x_{3}=\alpha+1
\end{array}\right]\mapsto\left[\begin{array}{c}
\left(\begin{array}{c}
1\\
0
\end{array}\right)\\
\left(\begin{array}{c}
0\\
1
\end{array}\right)\\
\left(\begin{array}{c}
1\\
1
\end{array}\right)
\end{array}\right],
\]

where we use the following rule for mapping $x_{i}$ individually:
$a_{0}\cdot\alpha^{0}+a_{1}\cdot\alpha^{1}+\ldots+a_{t-1}\cdot\alpha^{t-1}\mapsto\left(\begin{array}{c}
a_{0}\\
a_{1}\\
\vdots\\
a_{t-1}
\end{array}\right)$.

To summarize the notations of both scalar and vector coding, we represent
them in the Table~\ref{tab:notations}:

\begin{table}[h]
\caption{Notations of network coding}

\label{tab:notations} 

\begin{tabular}{|>{\centering}p{0.2\paperwidth}|c|c|}
\hline 
 & Scalar Coding & Vector coding\tabularnewline
\hline 
\hline 
Source Messages/Packets & $\begin{array}{c}
x_{1},\ldots,x_{h}\in\ensuremath{\mathbb{F}}_{q^{t}}\\
\underline{x}\in\ensuremath{\mathbb{F}}_{q^{t}}^{h}
\end{array}$ & $\begin{array}{c}
\underline{x}_{1},\ldots,\underline{x}_{h}\in\ensuremath{\mathbb{F}}_{q}^{t}\\
\underline{x}\in\ensuremath{\mathbb{F}}_{q}^{th}
\end{array}$\tabularnewline
\hline 
Global Coding Vectors Of Receiver $R_{j}$ & $\begin{array}{c}
\underline{a}_{j_{1}},\ldots,\underline{a}_{j_{\alpha l}}\in\ensuremath{\mathbb{F}}_{q^{t}}^{h}\\
\underline{b}_{j_{1}},\ldots,\underline{b}_{j_{\epsilon}}\in\ensuremath{\mathbb{F}}_{q^{t}}^{h}
\end{array}$ & $\begin{array}{c}
\boldsymbol{A}_{i_{1}},\ldots,\boldsymbol{A}_{i_{\alpha l}}\in\ensuremath{\mathbb{F}}_{q}^{t\times th}\\
\boldsymbol{B}_{j_{1}},\ldots,\boldsymbol{B}_{j_{\epsilon}}\in\ensuremath{\mathbb{F}}_{q}^{t\times th}
\end{array}$\tabularnewline
\hline 
Transfer Matrix Of Receiver $R_{j}$ & $\boldsymbol{A}_{j}\in\ensuremath{\mathbb{F}}_{q^{t}}^{s\times h}$ & $\boldsymbol{A}_{j}\in\ensuremath{\mathbb{F}}_{q}^{st\times th}$\tabularnewline
\hline 
Packets On Receiver $R_{j}$ & $\begin{array}{c}
y_{j_{1}},\ldots,y_{j_{s}}\in\ensuremath{\mathbb{F}}_{q^{t}}\\
\underline{y}\in\ensuremath{\mathbb{F}}_{q^{t}}^{s}
\end{array}$ & $\begin{array}{c}
\underline{y}_{j_{1}},\ldots,\underline{y}_{j_{s}}\in\ensuremath{\mathbb{F}}_{q}^{t}\\
\underline{y}\in\ensuremath{\mathbb{F}}_{q}^{st}
\end{array}$\tabularnewline
\hline 
\end{tabular}
\end{table}

\begin{claim}
By using the vector coding, the upper bound number of solutions increases
from $q^{tkh}$ to $q^{t^{2}kh}$. Therefore, vector network coding
offers more freedom in choosing the coding coefficients than does
scalar linear coding for equivalent alphabet sizes, and a smaller
alphabet size might be achievable \cite{Ebrahimi2011}.
\end{claim}

\section{Comparison between scalar and vector coding by the gap size}

In this study, we use vector messages in the extension field $\ensuremath{\mathbb{F}}_{q}^{t}$,
which results in equivalent solutions for scalar linear and vector
network coding with respect to alphabet size. We introduce a \textit{gap}
between the optimal scalar linear solution and our vector solution.
The gap represents the difference between the smallest field (alphabet)
size for which a scalar linear solution exists and the smallest alphatbet
size for which we can construct a vector solution. To calculate this
gap, we conduct the following steps:

\begin{algorithm}
\caption{Calculate the gap\label{alg:Calculate-the-gap}}

\begin{enumerate}
\item Find the lower bound of $r_{max,vector}$, which indicates a solvable
vector network coding of field size $q$ and dimension $t$ ($q_{v}=q^{t}$).
\item Find the upper bound of $r_{max,scalar}$, which indicates a optimal
scalar linear network coding in $\ensuremath{\mathbb{F}}_{q_{s}}$.
\item Because the vector solution in $\ensuremath{\mathbb{F}}_{q}^{t}$
is equivalent to the optimal scalar solution, we assign $r_{max,scalar}=r_{max,vector}$
to find $q_{s}$.
\item An achieved gap is calculated by $g=q_{s}-q_{v}$
\end{enumerate}
\end{algorithm}

Throughout this study, we show that vectors solutions significantly
reduce the required alphabet size by this gap. 

\clearpage
